{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a08124fc-ffee-4001-b0ec-c0580fcdc1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#——————————————————————1.WM,GM,CSF,Whole brain mask construction————————————————————\n",
    "#input\n",
    "#ribbon_path. ribbon文件的路径\n",
    "#wmpacr_path, wmparc文件路径\n",
    "#fmri_path, 功能像文件路径\n",
    "#out_Dir, where to save masks\n",
    "\n",
    "#输出\n",
    "#本地WM,GN,CSF，whole brain的mask 3D文件\n",
    "#WM,GN,CSF，whole brain的一维数组，便于后续分析\n",
    "def maskConstruction (ribbon_path, wmparc_path, fmri_path, out_Dir):\n",
    "    #——————————读取数据——————————\n",
    "    ribbon = nib.load(ribbon_path) #读取数据,注意此时仅仅是一个替代（或者说映像proxy），并未将数据加载到内存中\n",
    "    wmparc = nib.load(wmparc_path)\n",
    "\n",
    "    #——————————重采样之前，先定义输出文件路径——————————\n",
    "    #由于重采样之后会重新生成与功能像分辨率一致的结构像文件，因此需要定义输出文件的路径\n",
    "    ribbon_out = op.join(out_Dir, 'ribbon_out.nii.gz')#输出影像文件地址\n",
    "    wmparc_out = op.join(out_Dir, 'wmparc_out.nii.gz')\n",
    "\n",
    "    ribbonMat = op.join(out_Dir, 'ribbon_flirt.mat')#输出矩阵文件地址，这三个矩阵仅仅是函数需要，并没有什么用，事后将移除\n",
    "    wmparcMat = op.join(out_Dir, 'wmparc_flirt.mat')#输出矩阵文件地址\n",
    "    eyeMat = op.join(out_Dir, 'eye.mat')#创建一个单位阵进行刚体变换，实际上就是不变换。\n",
    "                                    #这是由于重采样其实使用了fsl的flirt配准函数，函数需要一个变换矩阵进行配准。但所有图形都已经配准好了，此时仅仅需要重采样\n",
    "    with open(eyeMat,'w') as fid: #设置为单位矩阵\n",
    "                fid.write('1 0 0 0\\n0 1 0 0\\n0 0 1 0\\n0 0 0 1')\n",
    "\n",
    "    #——————————开始重采样——————————\n",
    "    #调用fsl的FLIRT配准函数进行重采样，由于此时无需配准，因此变换矩阵都是单位阵，仅仅是函数需要\n",
    "    #重采样方法选用最近邻(nearestneighbour)。这是由于不能改变结构像的数值，因为一旦变化（如取平均），那么便无法与结构的编号进行匹配\n",
    "    #毕竟wmparc和ribbon里面的数值实际上就是不同组织的编号\n",
    "    flirt_ribbon = fsl.FLIRT(in_file=ribbon_path, out_file=ribbon_out,#ribbon原始文件以及输出文件的路径\n",
    "                                reference=fmri_path, apply_xfm=True,#用功能像来作为配准的参照\n",
    "                                in_matrix_file=eyeMat, out_matrix_file=ribbonMat, interp='nearestneighbour')\n",
    "    flirt_ribbon.run()\n",
    "    flirt_wmparc = fsl.FLIRT(in_file=wmparc_path, out_file=wmparc_out,\n",
    "                                    reference=fmri_path, apply_xfm=True,\n",
    "                                    in_matrix_file=eyeMat, out_matrix_file=wmparcMat, interp='nearestneighbour')\n",
    "    flirt_wmparc.run()\n",
    "\n",
    "    #————————读取重采样后的文件————————\n",
    "    #加上.get_fdata()后即可读取完整数据，得到一个多维数组\n",
    "    ribbon_flirt = nib.load(ribbon_out).get_fdata()\n",
    "    wmparc_flirt = nib.load(wmparc_out).get_fdata()\n",
    "\n",
    "    #————————创建mask————————\n",
    "    #根据https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT中的索引找出ribbon文件和wmparc文件中对应的灰质/白质/脑脊液位置\n",
    "            \n",
    "    # white & CSF matter mask\n",
    "    # indices are from FreeSurferColorLUT.txt\n",
    "\n",
    "    # Left-Cerebral-White-Matter, Right-Cerebral-White-Matter\n",
    "    ribbonWMstructures = [2, 41]#大脑皮层白质，基于ribbon\n",
    "\n",
    "    # Left-Cerebral-Cortex, Right-Cerebral-Cortex\n",
    "    ribbonGMstrucures = [3, 42]#大脑皮层灰质，基于ribbon\n",
    "\n",
    "    #下面的皮层下结构都是基于wmparc\n",
    "    # Cerebellar-White-Matter-Left, Brain-Stem, Cerebellar-White-Matter-Right\n",
    "    wmparcWMstructures = [7, 16, 46]#小脑白质，基于wmparc。这里还纳入了脑干，具体原因还需进一步查文献\n",
    "\n",
    "    # Left-Cerebellar-Cortex, Right-Cerebellar-Cortex, Thalamus-Left, Caudate-Left\n",
    "    # Putamen-Left, Pallidum-Left, Hippocampus-Left, Amygdala-Left, Accumbens-Left \n",
    "    # Diencephalon-Ventral-Left, Thalamus-Right, Caudate-Right, Putamen-Right\n",
    "    # Pallidum-Right, Hippocampus-Right, Amygdala-Right, Accumbens-Right\n",
    "    # Diencephalon-Ventral-Right\n",
    "    wmparcGMstructures = [8, 47, 10, 11, 12, 13, 17, 18, 26, 28, 49, 50, 51, 52, 53, 54, 58, 60]#皮层下灰质\n",
    "\n",
    "    # Fornix, CC-Posterior, CC-Mid-Posterior, CC-Central, CC-Mid-Anterior, CC-Anterior\n",
    "    wmparcCCstructures = [250, 251, 252, 253, 254, 255]#胼胝体\n",
    "\n",
    "    # Left-Lateral-Ventricle, Left-Inf-Lat-Vent, 3rd-Ventricle, 4th-Ventricle, CSF\n",
    "    # Left-Choroid-Plexus, Right-Lateral-Ventricle, Right-Inf-Lat-Vent, Right-Choroid-Plexus\n",
    "    wmparcCSFstructures = [4, 5, 14, 15, 24, 31, 43, 44, 63]#脑脊液\n",
    "\n",
    "    #——————————make masks，将上述索引与重采样后的ribbon和wmparc文件取交集，得到对应组织的位置，用0，1表示————————\n",
    "    WMmask = np.double(np.logical_and(np.logical_and(np.logical_or(np.logical_or(np.in1d(ribbon_flirt, ribbonWMstructures),\n",
    "                                                                        np.in1d(wmparc_flirt, wmparcWMstructures)),\n",
    "                                                            np.in1d(wmparc_flirt, wmparcCCstructures)),\n",
    "                                            np.logical_not(np.in1d(wmparc_flirt, wmparcCSFstructures))),\n",
    "                            np.logical_not(np.in1d(wmparc_flirt, wmparcGMstructures))))\n",
    "    CSFmask = np.double(np.in1d(wmparc_flirt, wmparcCSFstructures))\n",
    "    GMmask = np.double(np.logical_or(np.in1d(ribbon_flirt,ribbonGMstrucures),np.in1d(wmparc_flirt,wmparcGMstructures)))\n",
    "\n",
    "    #————————————————————write masks，将mask导出到本地备用——————————————\n",
    "    ref = nib.load(wmparc_out)#由于上述得到的mask是一维数组，因此需要导入wmparc_flirt作为参照，将矩阵维度还原\n",
    "\n",
    "    img = nib.Nifti1Image(WMmask.reshape(ref.shape).astype('<f4'), ref.affine)#astype函数用于将数组的数据类型转换为指定的数据类型。'<f4'是一个数据类型描述符，\n",
    "                                                                            #图像继承参照的affine，是图像空间到世界空间坐标的转换矩阵\n",
    "    WMmask_outPath = op.join(out_Dir,'WMmask.nii.gz')\n",
    "    nib.save(img, WMmask_outPath)\n",
    "\n",
    "    img = nib.Nifti1Image(CSFmask.reshape(ref.shape).astype('<f4'), ref.affine)\n",
    "    CSFmask_outPath = op.join(out_Dir,'CSFmask.nii.gz')\n",
    "    nib.save(img, CSFmask_outPath)\n",
    "\n",
    "    img = nib.Nifti1Image(GMmask.reshape(ref.shape).astype('<f4'), ref.affine)\n",
    "    GMmask_outPath = op.join(out_Dir,'GMmask.nii.gz')\n",
    "    nib.save(img, GMmask_outPath)\n",
    "\n",
    "    # delete temporary files\n",
    "    cmd = 'rm {} {} {}'.format(eyeMat, ribbonMat, wmparcMat)\n",
    "    call(cmd,shell=True)\n",
    "\n",
    "    #——————————读取mask，直接用于后续分析——————————\n",
    "    tmpWM = nib.load(WMmask_outPath)#读取白质mask\n",
    "    nRows, nCols, nSlices = tmpWM.header.get_data_shape()#获取数据维度结构\n",
    "    maskWM = np.asarray(tmpWM.dataobj).reshape(nRows*nCols*nSlices, order='F') > 0#将数据转换为一维数组,用逻辑值表示\n",
    "\n",
    "    tmpCSF = nib.load(CSFmask_outPath)\n",
    "    maskCSF = np.asarray(tmpCSF.dataobj).reshape(nRows*nCols*nSlices, order='F')  > 0\n",
    "\n",
    "    tmpGM = nib.load(GMmask_outPath)\n",
    "    maskGM = np.asarray(tmpGM.dataobj).reshape(nRows*nCols*nSlices, order='F') > 0\n",
    "\n",
    "    maskAll_1D  = np.logical_or(np.logical_or(maskWM, maskCSF), maskGM)\n",
    "    maskWM_1D  = maskWM[maskAll_1D]\n",
    "    maskCSF_1D = maskCSF[maskAll_1D]\n",
    "    maskGM_1D  = maskGM[maskAll_1D]\n",
    "\n",
    "    #——————————输出值——————————\n",
    "    return maskAll_1D, maskWM_1D, maskCSF_1D, maskGM_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f79b670-fa19-4bfa-913a-411d2b38f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#——————————————————————2. deneam normalization————————————————————\n",
    "#输入\n",
    "#fmri_path, 功能像文件路径。注意导入的是cifti还是nifti格式\n",
    "#maskAll, 全脑mask，来自于上一个函数的输出\n",
    "#iscifti，whether the fmri data is cifti\n",
    "\n",
    "#输出\n",
    "#demean_data,标准化后的fmri数据，二维数组， voxel×time\n",
    "def demean(fmri_path, maskAll, iscifti = True):  \n",
    "    #——————————读取fMRI数据文件——————————\n",
    "    img0 = nib.load(fmri_path) #读取影像文件，注意此时数据并没有加载到内存中，仅仅是一个proxy\n",
    "    img0_data = img0.get_fdata() #读取完整数据，由于数据量很大，耗时较长\n",
    "    if iscifti:\n",
    "        img0_masked = img0_data.T #cifti的文件是二维数组，时间×voxel，为了与后面一致，将其转置\n",
    "        #另外，cifti的文件本身只包含了脑组织，所以并不需要额外的mask\n",
    "    else:  \n",
    "        nrow, ncol, nslice, nTR = img0.header.get_data_shape() #获取数据维度结构, 此时是一个四维数据，分别是：行，列，切片，时间点\n",
    "        #——————————数据维度转换——————————\n",
    "        img0_2D = img0_data.reshape((nrow * ncol * nslice, nTR),order = 'F')#将四维数据转换成二维，前三个维度合并为一个\n",
    "                                                                        #order=‘F’表示第一个维度最先展开(nrow)\n",
    "                                                                        #展开方式也可更换为C，但要保证后续所有的展开方式一致\n",
    "        img0_2D.shape #此时的img0_2D是二维数据，每一行是一个体素的时间序列\n",
    "        #——————————利用全脑mask提取fmri脑组织的信号——————————\n",
    "        img0_masked = img0_2D[maskAll,:] #提取脑组织信号\n",
    "        \n",
    "    #——————————去均值处理————————————\n",
    "    #voxel_means = img0_masked.mean(1)[:,np.newaxis] #为便于后续减去该均值，需要增加一个维度，变成二维数组\n",
    "    #img_demean = img0_masked - voxel_means\n",
    "    img_demean= img0_masked - img0_masked.mean()\n",
    "    return img_demean #返回去均值后的fmri数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0297d6ce-b2b9-47c5-9ef5-11e60d0455c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#——————————————————————3.detrending————————————————————\n",
    "#输入\n",
    "#demean_fmri, 标准化后的fmri数据，注意不是路径。该数据为上一个函数的输出结果\n",
    "\n",
    "#输出\n",
    "#detrending_data,去趋势后的fmri数据，二维数组， voxel×time\n",
    "def detrending(demean_fmri):\n",
    "    #构建设计矩阵\n",
    "    timepoints = np.arange(demean_fmri.shape[1])[:,np.newaxis]#生成二维数据（1200×1），不过只有一列数据，从0到1199的时间序列\n",
    "    X = np.concatenate((np.ones([demean_fmri.shape[1],1]), timepoints), axis=1)#生成设计矩阵，第一列是截距（全为1），第二列是时间序列\n",
    "    #回归模型\n",
    "    fit = np.linalg.lstsq(X, demean_fmri.T, rcond=None)[0]# 获取回归系数,rcond意味着是否设置阈值来去掉较小的奇异值，此处不去掉\n",
    "\n",
    "    #————————————aggressive regression——————————\n",
    "    #fittedvalues = np.dot(X, fit)#使用矩阵乘法得到拟合值\n",
    "    #————————————soft regression——————————\n",
    "    X1 = X[:,1][:,np.newaxis]\n",
    "    fit1 = fit[1,:][np.newaxis,:]\n",
    "\n",
    "    #此外，需要注意的是原始数据每一行才是一个voxel，需要先转置，将每一个voxel变为一列才纳入模型\n",
    "    #由于现在的data有很多列，因此是每一列单独进行拟合，回归系数也变为一个2（截距，时间）×voxel\n",
    "    fittedvalues = np.dot(X1, fit1)#使用矩阵乘法得到拟合值\n",
    "\n",
    "    detrending_data = demean_fmri - fittedvalues.T #原始信号减去拟合值完成去趋势，需要注意的是此时的拟合值需要先转置回来与原始数据结构一致\n",
    "    return detrending_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff76a7f4-ba7d-4984-8b4a-4425f7d0840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#——————————————————————4.regression denoising————————————————————\n",
    "#输入\n",
    "#motionPar_path 头动文件路径\n",
    "#maskWM，基于nifti数据生成的白质mask\n",
    "#maskCSF，基于nifti数据生成的脑脊液mask\n",
    "#maskGM,基于nifti数据生成的灰质mask，最终只分数灰质部分\n",
    "#dt_Vdata, 去趋势后得到的nifti数据，用于生成信号\n",
    "#dt_Cdata, 若分析的是cifti文件，那么回归的因变量使用这个去趋势后的数据\n",
    "#Rmotion,是否要回归掉头动。如果是FIX-ICA数据的话，头动已经回归掉了，此时无需再做一遍\n",
    "#iscifti，分析的数据是否为cifti格式\n",
    "def signalRegress(motionPar_path, maskWM, maskCSF, maskGM, dt_Vdata, dt_Cdata, Rmotion=False, RGS = False, iscifti = True):\n",
    "    motionPar = np.loadtxt(motionPar_path)#读取头动参数\n",
    "    WM_mean = dt_Vdata[maskWM,:].mean(0)[:,np.newaxis]#白质信号，基于nifti生成\n",
    "    CSF_mean = dt_Vdata[maskCSF,:].mean(0)[:,np.newaxis]#脑脊液信号，基于nifti生成\n",
    "    Global_mean = dt_Vdata.mean(0)[:,np.newaxis]#全局信号，基于nifti生成\n",
    "    X = np.concatenate((np.ones([dt_Vdata.shape[1],1]), WM_mean, CSF_mean), axis=1)\n",
    "    if Rmotion:\n",
    "        X = np.concatenate((X, motionPar), axis=1)#加入头动\n",
    "    if RGS:\n",
    "        X = np.concatenate((X, Global_mean), axis=1)#加入全局信号\n",
    "    #——————————————进行回归————————————————\n",
    "    if iscifti:\n",
    "        dt_data = dt_Cdata\n",
    "    else:\n",
    "        dt_data = dt_Vdata[maskGM,:]\n",
    "    fit = np.linalg.lstsq(X, dt_data.T, rcond=None)[0]# 获取回归系数,rcond意味着是否设置阈值来去掉较小的奇异值，此处不去掉\n",
    "    #此外，需要注意的是原始数据每一行才是一个voxel，需要先转置，将每一个voxel变为一列才纳入模型\n",
    "    #由于现在的data有很多列，因此是每一列单独进行拟合，回归系数也变为一个2（截距，时间）×voxel\n",
    "    #————————————aggressive regression——————————\n",
    "    #fittedvalues = np.dot(X, fit)#使用矩阵乘法得到拟合值\n",
    "    #——————————————————soft regression——————————————\n",
    "    X1 = X[:,1:]\n",
    "    fit1 = fit[1:,:]\n",
    "    \n",
    "    fittedvalues = np.dot(X1, fit1)#使用矩阵乘法得到拟合值\n",
    "    denoised_data = dt_data - fittedvalues.T #原始信号减去拟合值完成去组织信号，需要注意的是此时的拟合值需要先转置回来与原始数据结构一致\n",
    "    return denoised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19a81c55-40f3-41c7-a897-0df75114fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flitering(data, TR, high=0.01, low=0.08):\n",
    "    data_flitered = clean(data.T, detrend=False, standardize=False, #用butterworth滤波\n",
    "                   t_r=TR, high_pass=high, low_pass=low)\n",
    "    return data_flitered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84a5aeb-8222-4027-9361-36d05311b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#——————————————————————导入所需包——————————————————————\n",
    "import nibabel as nib #影像处理所使用的库\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as op #操作路径拼接的库\n",
    "import nipype.interfaces.fsl as fsl #fsl交互的库\n",
    "from subprocess import call #调用call函数使用cmd\n",
    "from nilearn.signal import clean\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50ef7b77-1c32-40ed-be97-988ce06442b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#——————————————————————设置文件路径————————————————————\n",
    "cifti_dir = [\"/mnt/f/HCP1200_1\",\"/mnt/g/HCP1200_2\"] #HCP cifti功能像数据的存放路径, 由于空间不足分别存在两个盘\n",
    "nifti_dir = \"/mnt/h/HCP1200/REST2_preproc\"\n",
    "structure_dir=\"/mnt/h/HCP1200/Structure\" #结构像数据存放的路径\n",
    "\n",
    "session = [\"rfMRI_REST1_LR\", \"rfMRI_REST2_LR\"][1] #待分析的任务, 逐一分析\n",
    "\n",
    "subjects = np.loadtxt(\"/mnt/e/liuwei/results/HCP1200fixsub.txt\",dtype = str)#之前分析的所有被试编号,工作站路径\n",
    "#subjects = np.loadtxt(\"/mnt/d/LWfiles/liuwei/HCP1200sub.txt\",dtype = str)\n",
    "\n",
    "ribbon_path = np.array([op.join(structure_dir,subjects[i],\"MNINonLinear/ribbon.nii.gz\") for i in range(len(subjects))]) #1018个被试的ribbon文件路径\n",
    "print(type(ribbon_path))\n",
    "checkRibbon = np.array([op.exists(i) for i in ribbon_path])#检查文件路径是否正确\n",
    "ribbon_path = ribbon_path[checkRibbon]\n",
    "\n",
    "wmparc_path = np.array([op.join(structure_dir,subjects[i],\"MNINonLinear/wmparc.nii.gz\") for i in range(len(subjects))]) #1018个被试的ribbon文件路径\n",
    "checkWmparc = np.array([op.exists(i) for i in wmparc_path])#检查文件路径是否正确\n",
    "wmparc_path = wmparc_path[checkWmparc]\n",
    "\n",
    "cifti_path = np.array([\"{0}/{1}_3T_rfMRI_REST_fix/{1}/MNINonLinear/Results/{2}/{2}_Atlas_MSMAll_hp2000_clean.dtseries.nii\"\n",
    "                 .format(i,j,session) for i in cifti_dir for j in subjects])#待分析的cifti文件路径\n",
    "checkC = np.array([op.exists(i) for i in cifti_path])#检查文件路径是否正确\n",
    "cifti_path = cifti_path[checkC]\n",
    "\n",
    "if session == \"rfMRI_REST2_LR\" :\n",
    "    nifti_path = np.array([\"{0}/{1}_3T_rfMRI_REST2_preproc/{1}/MNINonLinear/Results/{2}/{2}.nii.gz\"\n",
    "                     .format(nifti_dir,j,session) for j in subjects])\n",
    "    motionPar_path = np.array([\"{0}/{1}_3T_rfMRI_REST2_preproc/{1}/MNINonLinear/Results/{2}/Movement_Regressors_dt.txt\"\n",
    "                 .format(nifti_dir,j,session) for j in subjects])\n",
    "elif session ==  \"rfMRI_REST1_LR\":\n",
    "     nifti_path = np.array([\"/mnt/i/{0}/{1}/{0}.nii.gz\".format(session,j) for j in subjects])\n",
    "     motionPar_path = np.array([\"/mnt/i/{0}/{1}/Movement_Regressors_dt.txt\".format(session,j) for j in subjects])\n",
    "    \n",
    "checkN = np.array([op.exists(i) for i in nifti_path])\n",
    "nifti_path = nifti_path[checkN]\n",
    "checkMotion = np.array([op.exists(i) for i in motionPar_path])\n",
    "motionPar_path = motionPar_path[checkMotion]\n",
    "\n",
    "out_Dir = op.join(\"/mnt/e/HCP1200denoised/intercept\",session)#设置输出文件夹，可以根据自己方便新建一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef5f66b5-d93d-4a33-8dd1-75bd322b69a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(ribbon_path, wmparc_path, nifti_path, cifti_path, motionPar_path,#所需文件的路径\n",
    "             subNum, outDir,session, high_pass, low_pass):\n",
    "   #start = time.time()\n",
    "    out_Dir = op.join(outDir, subNum)\n",
    "    os.makedirs(out_Dir, exist_ok=True)\n",
    "    maskAll, maskWM, maskCSF, maskGM = maskConstruction(ribbon_path, wmparc_path, nifti_path, out_Dir)\n",
    "    V_demean = demean(nifti_path, maskAll, False) #对nifti文件标准化\n",
    "    C_demean = demean(cifti_path, maskAll, True) #对cifti文件标准化\n",
    "    V_dt = detrending(V_demean) #对nifti文件去趋势\n",
    "    C_dt = detrending(C_demean) #对cifti文件去趋势\n",
    "    C_denoising = signalRegress(motionPar_path, maskWM, maskCSF, maskGM, dt_Vdata = V_dt, dt_Cdata = C_dt, Rmotion=False, RGS = True, iscifti = True)\n",
    "    TR = nib.load(nifti_path).header.structarr['pixdim'][4]\n",
    "    data_flitered = flitering(C_denoising, TR, high=high_pass, low=low_pass)\n",
    "    raw_cifti = nib.load(cifti_path)\n",
    "    denoised_cifti = nib.Cifti2Image(data_flitered, #数据文件，时间×顶点二维数组\n",
    "                                header = raw_cifti.header, #cifti的头文件\n",
    "                                nifti_header=raw_cifti.nifti_header)\n",
    "    #将文件保存到本地\n",
    "    nib.save(denoised_cifti, op.join(out_Dir, \"{}_denoised_{}.dtseries.nii\".format(subNum, session)))\n",
    "    #end = time.time()\n",
    "    #print(\"被试{}处理结束，剩余{}个被试，用时为{}秒\".format(subjects[i], str(len(ribbon_path)-i-1), str(end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8740b3d-bec0-4917-9439-7329fa649d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subNum = subjects[0]\n",
    "out_Dir = op.join(out_Dir, subNum)\n",
    "maskAll, maskWM, maskCSF, maskGM = maskConstruction(ribbon_path[0], wmparc_path[0], nifti_path[0], out_Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56072b-9de0-4863-aa02-18f0ed4886d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_demean = demean(nifti_path[0], maskAll, False) #对nifti文件标准化\n",
    "C_demean = demean(cifti_path[0], maskAll, True) #对cifti文件标准化\n",
    "V_dt = detrending(V_demean) #对nifti文件去趋势\n",
    "C_dt = detrending(C_demean) #对cifti文件去趋势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5bf84a-23e2-422c-8bf8-ee17cbf4800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ribbon_path)):\n",
    "    if i < 134:\n",
    "        continue\n",
    "    start = time.time()\n",
    "    try:\n",
    "        pipeline(ribbon_path[i], wmparc_path[i], nifti_path[i], cifti_path[i], motionPar_path[i],\n",
    "                                   subjects[i], out_Dir,session, 0.01, 0.08)\n",
    "    except:\n",
    "        print(\"{}数据出现异常\".format(subjects[i]))\n",
    "    end = time.time()\n",
    "    print(\"被试{}处理结束，剩余{}个被试，用时为{}秒\".format(subjects[i], str(len(ribbon_path)-i-1), str(end - start)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
